from typing import Any

from agentwerkstatt.llms.base import BaseLLM
from agentwerkstatt.tools.base import BaseTool
from agentwerkstatt.tools.schemas import ToolSchema, InputSchema, InputProperty


class ReflectionTool(BaseTool):
    """A tool to check if the generated final answer matches the initial request."""

    def __init__(self, llm_client: BaseLLM):
        self._llm_client = llm_client

    def get_name(self) -> str:
        """Returns the programmatic name of the tool."""
        return "reflection"

    def get_description(self) -> str:
        """Returns a human-readable description of what the tool does."""
        return """
            Checks if the generated final answer matches the initial request.
            Use it to verify that the final answer is relevant and complete.
            Use it as the FINAL step in your execution process.
            After using this tool, you MUST provide a final_answer with no more tool calls.
            """.strip()

    def get_schema(self) -> ToolSchema:
        """Returns the JSON schema for the tool's inputs."""
        return ToolSchema(
            name=self.get_name(),
            description=self.get_description(),
            input_schema=InputSchema(
                properties={
                    "initial_request": InputProperty(
                        type="string",
                        description="The initial request from the user.",
                    ),
                    "final_answer": InputProperty(
                        type="string",
                        description="The final answer generated by the agent.",
                    ),
                },
                required=["initial_request", "final_answer"],
            ),
        )

    def execute(self, **kwargs: Any) -> dict[str, Any]:
        """Executes the tool with the given keyword arguments."""
        initial_request = kwargs.get("initial_request")
        final_answer = kwargs.get("final_answer")
        if not initial_request or not final_answer:
            return {"error": "Initial request and final answer must be provided."}

        prompt = f"""
            Does the following final answer match the initial request?
            Initial Request: {initial_request}
            Final Answer: {final_answer}

            Evaluate whether the final answer:
            1. Directly addresses the initial request
            2. Is complete and thorough
            3. Provides all requested deliverables

            Answer with "APPROVED" if the answer fully meets the request, or "NEEDS_REVISION" if it doesn't.
            Then provide a brief explanation of your decision.

            IMPORTANT: If you respond with "APPROVED", the agent will stop and provide this as the final answer.
            If you respond with "NEEDS_REVISION", explain what's missing or needs improvement.
            """.strip()
        try:
            reflection = self._llm_client.query(prompt=prompt, context="")
            return {"reflection": reflection}
        except Exception as e:
            return {"error": f"Failed to generate reflection: {e}"}
